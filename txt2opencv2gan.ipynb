{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip isntall -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import importlib\n",
    "import config\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "importlib.reload(config)\n",
    "# from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# if device != \"cuda\":\n",
    "#     raise Exception(\"Can't launch CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     dataset = load_dataset('DonkeySmall/OCR-English-Printed-12', split='train[:1%]')\n",
    "#     print(\"Данные загружены успешно!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Ошибка при загрузке набора данных: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_show(img, key='q', time=0, window_name='cv2'):\n",
    "    print(time)\n",
    "    cv2.imshow(window_name, img)\n",
    "    if time:\n",
    "        cv2.waitKey(time)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        printed_key = cv2.waitKey(0)\n",
    "        if printed_key == key:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def stack_images(images, direction='vertical'):\n",
    "    if not images or any(img is None for img in images):\n",
    "        raise ValueError(\n",
    "            \"Список изображений пуст или содержит недопустимые значения\")\n",
    "\n",
    "    if direction == 'horizontal':\n",
    "        min_height = min(img.shape[0] for img in images)\n",
    "        resized_images = [cv2.resize(img, (int(img.shape[1] * (min_height / img.shape[0])), min_height))\n",
    "                          for img in images]\n",
    "        stacked_image = np.hstack(resized_images)\n",
    "    elif direction == 'vertical':\n",
    "        min_width = min(img.shape[1] for img in images)\n",
    "        resized_images = [cv2.resize(img, (min_width, int(img.shape[0] * (min_width / img.shape[1]))))\n",
    "                          for img in images]\n",
    "        stacked_image = np.vstack(resized_images)\n",
    "    else:\n",
    "        raise ValueError(\"direction должен быть 'horizontal' или 'vertical'\")\n",
    "\n",
    "    return stacked_image\n",
    "\n",
    "\n",
    "def add_noise_and_distortion(img):\n",
    "    noise = np.random.uniform(0, 50, img.shape).astype(np.uint8)\n",
    "    noisy_img = cv2.add(img, noise)\n",
    "\n",
    "    # искажения с помощью линий\n",
    "    num_lines = np.random.randint(0, 10)\n",
    "    for _ in range(num_lines):\n",
    "        x1, y1 = np.random.randint(\n",
    "            0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "        x2, y2 = np.random.randint(\n",
    "            0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "        cv2.line(noisy_img, (x1, y1), (x2, y2), (0, 0, 0), 1)\n",
    "\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_image(text, img=None, noise=False, max_char_y_offset=0.025, max_char_x_offset=0.025):\n",
    "    gen_height, gen_width = image_size, image_size * 4\n",
    "\n",
    "    if img is None:\n",
    "        img = np.ones((gen_height, gen_width), dtype=np.uint8) * 255  # белый фон\n",
    "\n",
    "    # Используем первый шрифт из списка\n",
    "    font_path = config.fonts_paths[0]\n",
    "    font_size = random.randint(20, 35)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    pil_img = Image.fromarray(img, mode='L')  # Устанавливаем режим 'L' для одноканального изображения\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    # Находим позицию текста\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_size = (bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "\n",
    "    # Уменьшаем размер шрифта, если текст не помещается\n",
    "    while text_size[0] > img.shape[1] or text_size[1] > img.shape[0]:\n",
    "        font_size -= 1\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_size = (bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "\n",
    "    text_x = (img.shape[1] - text_size[0]) // 2\n",
    "    text_y = (img.shape[0] - text_size[1]) // 2\n",
    "\n",
    "    # Рисуем текст с небольшими случайными смещениями\n",
    "    for char in text:\n",
    "        bbox = draw.textbbox((text_x, text_y), char, font=font)\n",
    "        char_width = bbox[2] - bbox[0]\n",
    "        char_height = bbox[3] - bbox[1]\n",
    "\n",
    "        x_offset = random.randint(int(-char_width * max_char_x_offset), int(char_width * max_char_x_offset))\n",
    "        y_offset = random.randint(int(-char_height * max_char_y_offset), int(char_height * max_char_y_offset))\n",
    "        draw.text((text_x + x_offset, text_y + y_offset), char, font=font, fill=0)  # Черный текст\n",
    "\n",
    "        text_x += char_width  # Сдвигаем на ширину текущей буквы\n",
    "\n",
    "    img = np.array(pil_img)  # Преобразуем обратно в формат OpenCV\n",
    "\n",
    "    return add_noise_and_distortion(img) if noise else img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "\n",
    "# for _ in range(6):\n",
    "#     text = random.choice(config.texts)\n",
    "#     result = generate_text_image(text, noise=False)\n",
    "#     images.append(result[0])\n",
    "\n",
    "# for _ in range(6):\n",
    "#     text = random.choice(config.texts)\n",
    "#     result = generate_text_image(text, noise=True)\n",
    "#     images.append(result[0])\n",
    "\n",
    "# stacked_images = stack_images(images)\n",
    "# cv2_show(stacked_images, time=5000)\n",
    "\n",
    "\n",
    "# for _ in range(1):\n",
    "#     img = generate_text_image(random.choice(config.texts), noise=False)\n",
    "#     cv2_show(img, time=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size * 4)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.num_samples = len(texts)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        img = generate_text_image(text)\n",
    "        # print(\"Real image shape:\", img.shape)\n",
    "        img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size * (image_size * 4), 1024),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(4096, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), image_size * (image_size * 4))\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size * (image_size * 4), 32_768),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(32_768, 32_768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32_768, image_size * (image_size * 4)),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 1, image_size, image_size * 4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "dataset = TextDataset(config.texts)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "output_dir = datetime.datetime.now().strftime(\"TEXT_GAN_%Y-%m-%d_%H-%M-%S\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        netD.zero_grad()\n",
    "        real = data.to(device)\n",
    "        # print(real.shape)\n",
    "        batch_size = real.size(0)\n",
    "        labels = torch.full((batch_size,), 1.0, dtype=torch.float, device=device)\n",
    "        output = netD(real).view(-1)\n",
    "        # print(output.shape, labels.shape)\n",
    "        lossD_real = criterion(output, labels)\n",
    "        lossD_real.backward()\n",
    "\n",
    "        noise = real.view(batch_size, 1, image_size * (image_size * 4))\n",
    "        fake = netG(noise)\n",
    "        labels.fill_(0.0)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        lossD_fake = criterion(output, labels)\n",
    "        lossD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        labels.fill_(1.0)\n",
    "        output = netD(fake).view(-1)\n",
    "        lossG = criterion(output, labels)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        # print(f\"Batch {i} / {batch_size}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{epochs}] Loss D: {lossD_real + lossD_fake}, Loss G: {lossG}\")\n",
    "    save_image(fake.data, f\"{output_dir}/fake_samples_epoch_{epoch}.png\", normalize=True)\n",
    "    # avg_discriminator_loss = sum_discriminator_loss / batches\n",
    "    # print(f\"Elapsed time: {time.time() - start} seconds\")\n",
    "    # print(f\"Avg D Loss: {avg_discriminator_loss} Avg D Loss: {avg_generator_loss}\")\n",
    "    fake = fake.cpu().detach()\n",
    "    real = real.cpu().detach()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(8):\n",
    "        ax = plt.subplot(4, 2, i + 1)\n",
    "        plt.imshow(real[i].reshape(image_size, image_size * 4), cmap=\"gray_r\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.title(f\"{epoch} epoch\")\n",
    "    plt.savefig(f\"{output_dir}/{epoch}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(8):\n",
    "        ax = plt.subplot(4, 2, i + 1)\n",
    "        plt.imshow(fake[i].reshape(image_size, image_size * 4), cmap=\"gray_r\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.title(f\"{epoch} epoch\")\n",
    "    plt.savefig(f\"{output_dir}/{epoch}.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
